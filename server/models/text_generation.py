import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from rouge_score import rouge_scorer

# Load the GPT-2 text generation model
def load_model(model_dir, device):
    model = AutoModelForCausalLM.from_pretrained(model_dir).to(device)
    model.eval()
    return model


# Load the GPT-2 tokenizer
def load_tokenizer(model_dir):
    tokenizer = AutoTokenizer.from_pretrained(model_dir)
    tokenizer.pad_token = tokenizer.eos_token  # Ensure pad_token is set
    return tokenizer


# Generate text using the GPT-2 model
def generate_text(prompt, model, tokenizer, max_length=512, num_beams=5, early_stopping=True, device="cuda"):
    """
    Generate text based on the input prompt.
    Args:
        prompt (str): The input text/prompt for generation.
        model: The fine-tuned GPT-2 model.
        tokenizer: The GPT-2 tokenizer.
        max_length (int): Maximum length of the generated text.
        num_beams (int): Number of beams for beam search (set to 1 for greedy decoding).
        early_stopping (bool): Whether to stop generation early when the model predicts an end token.
        device (str): Device to run the model on ('cuda' or 'cpu').
    Returns:
        str: The generated text.
    """
    inputs = tokenizer(prompt, return_tensors="pt", padding=True, truncation=True).to(device)
    with torch.no_grad():
        outputs = model.generate(
            inputs["input_ids"],
            attention_mask=inputs["attention_mask"],
            max_length=max_length,
            num_beams=num_beams,
            early_stopping=early_stopping
        )
    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return generated_text


# Compute ROUGE-L score
def compute_rouge(generated_text, reference_text):
    """
    Compute the ROUGE-L score between the generated text and reference text.
    Args:
        generated_text (str): The text generated by the model.
        reference_text (str): The ground truth/reference text.
    Returns:
        float: The ROUGE-L F-measure score.
    """
    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)
    scores = scorer.score(reference_text, generated_text)
    return scores['rougeL'].fmeasure